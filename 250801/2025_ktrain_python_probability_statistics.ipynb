{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhNBrcLqisqJ"
      },
      "source": [
        "## 실습 공통 준비 사항\n",
        "\n",
        "모든 실습 문제는 seaborn 라이브러리에 내장된 Iris(붓꽃) 데이터셋을 사용합니다.\n",
        "\n",
        "아래 코드를 실행하여 데이터를 준비하고, numpy 배열로 변환하여 사용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_ZUeUHq6jkFO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 특징 데이터 shape: (150, 4)\n",
            "전체 라벨 데이터 shape: (150,)\n",
            "첫 번째 데이터: [5.1 3.5 1.4 0.2], 라벨: setosa\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Iris 데이터셋 로드\n",
        "iris_sns = sns.load_dataset('iris')\n",
        "\n",
        "# 데이터셋을 특징(X)과 라벨(y)로 분리\n",
        "features_all = iris_sns.drop('species', axis=1).to_numpy()\n",
        "labels_all = iris_sns['species'].to_numpy()\n",
        "feature_names = iris_sns.columns[:-1]\n",
        "\n",
        "# 데이터 확인\n",
        "print(f\"전체 특징 데이터 shape: {features_all.shape}\")\n",
        "print(f\"전체 라벨 데이터 shape: {labels_all.shape}\")\n",
        "print(f\"첫 번째 데이터: {features_all[0]}, 라벨: {labels_all[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2rSgzSXjFa9"
      },
      "source": [
        "## 실습 문제 1.1: 데이터의 산술 평균 계산하기\n",
        "\n",
        "**설명**: \\*\\*평균(mean)\\*\\*은 주어진 데이터셋의 모든 값을 더한 후 데이터의 개수로 나눈 값으로, 데이터의 중심을 나타내는 가장 기본적인 **기술 통계량**입니다. 150개 Iris 데이터의 '꽃받침 길이'(`sepal_length`) 전체의 산술 평균을 계산하여 이 데이터셋의 중심 경향성을 파악해 보세요.\n",
        "\n",
        "$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - `features_all`에서 첫 번째 열(꽃받침 길이) 데이터를 사용하세요.\n",
        "  - 이 데이터의 모든 요소를 더하고, 데이터의 개수(150)로 나누어 평균을 계산하는 `calculate_mean` 함수를 완성하세요.\n",
        "  - 계산된 평균을 출력하여 150개 꽃받침 길이 데이터의 중심 값을 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vsUQRHYFjE0_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_mean(data: np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  주어진 numpy 배열의 산술 평균을 계산합니다.\n",
        "\n",
        "  Args:\n",
        "    data: 1차원 숫자 데이터가 담긴 numpy 배열\n",
        "\n",
        "  Returns:\n",
        "    데이터의 평균값\n",
        "  \"\"\"\n",
        "  return data.sum() / len(data)\n",
        "\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IwAHYpnAjgCT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "붓꽃 데이터의 꽃받침 길이(sepal length)의 평균은? 5.8433\n"
          ]
        }
      ],
      "source": [
        "sepal_length_data = features_all[:, 0]\n",
        "mean_value = calculate_mean(sepal_length_data)\n",
        "print(f\"붓꽃 데이터의 꽃받침 길이(sepal length)의 평균은? {mean_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGKVpF83jzQR"
      },
      "source": [
        "## 실습 문제 1.2 (개정판): 표본 분산과 `ddof`의 이해\n",
        "\n",
        "**설명**: \\*\\*분산(variance)\\*\\*과 \\*\\*표준편차(standard deviation)\\*\\*는 데이터가 평균으로부터 얼마나 흩어져 있는지를 나타내는 **변동성**의 척도입니다. 이번 실습에서는 모집단의 분산을 더 잘 추정하기 위한 \\*\\*표본 분산(sample variance)\\*\\*을 계산합니다.\n",
        "\n",
        "> **💡 왜 n-1로 나눌까요? (자유도)**\n",
        "> 우리가 가진 데이터는 전체 붓꽃(모집단)에서 추출한 **표본**입니다. 표본의 평균($\\\\bar{x}$)은 실제 모집단의 평균($\\\\mu$)과 약간의 차이가 있으며, 이로 인해 분산이 실제보다 작게 계산되는 경향이 있습니다. 분모를 `n` 대신 `n-1`(**자유도**, degrees of freedom)로 사용하면 이 편향을 보정하여, 모집단의 분산을 더 잘 추정할 수 있습니다.\n",
        "\n",
        "> **⚠️ 라이브러리별 기본값의 함정: `ddof`란?**\n",
        "> `ddof`는 \\*\\*\"Delta Degrees of Freedom\"\\*\\*의 약자로, 분모에서 `n`으로부터 뺄 값을 지정하는 파라미터입니다.\n",
        ">\n",
        ">   - **NumPy (`np.var`)**: 공학, 과학 등 범용 계산에 중점을 두므로, 주어진 데이터를 '모집단'으로 간주하는 `ddof=0` (즉, `n`으로 나누기)을 기본값으로 사용합니다.\n",
        ">   - **Pandas (`Series.var`)**: 통계 분석을 주 목적으로 하므로, 데이터가 '표본'이라는 가정하에 `ddof=1` (즉, `n-1`로 나누기)을 기본값으로 사용합니다.\n",
        ">\n",
        "> 이 차이를 이해하는 것은 정확한 통계 계산을 위해 매우 중요합니다\\!\n",
        "\n",
        "$$s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\quad , \\quad s = \\sqrt{s^2}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이' 데이터를 사용하여, 분모를 `n-1`로 나누는 **표본 분산**과 **표본 표준편차**를 계산하는 `calculate_variance_std` 함수를 직접 구현하세요.\n",
        "  - 구현한 함수의 결과와 `numpy.var()`, `pandas.Series.var()` 함수의 결과를 비교하세요.\n",
        "  - `numpy.var()`에 `ddof=1` 인자를 전달했을 때, 직접 구현한 결과 및 Pandas의 결과와 일치하는지 확인하여 `ddof`의 역할을 검증하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0EwlylOcj2Js"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_variance_std(data: np.ndarray) -> tuple[float, float]:\n",
        "  \"\"\"\n",
        "  주어진 numpy 배열의 표본 분산(n-1)과 표본 표준편차를 계산합니다.\n",
        "  \"\"\"\n",
        "\n",
        "  s2 = ((data-mean_value)**2).sum() / (len(data)-1)\n",
        "  s1 = np.sqrt(s2)\n",
        "\n",
        "  return (s2,s1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mp_EPKqJ079z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. 직접 구현한 함수 결과 (n-1로 나눔) ---\n",
            "표본 분산: 0.685694\n",
            "표본 표준편차: 0.828066\n",
            "\n",
            "--- 2. NumPy 결과 비교 ---\n",
            "NumPy 모분산 (np.var, ddof=0 기본값): 0.681122  <-- (결과 다름!)\n",
            "NumPy 표본 분산 (np.var, ddof=1): 0.685694  <-- (결과 일치!)\n",
            "\n",
            "--- 3. Pandas 결과 비교 ---\n",
            "Pandas 표본 분산 (.var(), ddof=1 기본값): 0.685694 <-- (결과 일치!)\n",
            "\n",
            "--- 4. 최종 검증 ---\n",
            "직접 구현한 표본 분산이 NumPy(ddof=1) 및 Pandas의 결과와 일치하는가? 성공\n"
          ]
        }
      ],
      "source": [
        "# 1. 데이터 준비\n",
        "sepal_length_data = features_all[:, 0]\n",
        "sepal_length_series = pd.Series(sepal_length_data) # Pandas용 데이터\n",
        "\n",
        "# 2. 직접 구현한 함수 결과\n",
        "my_variance, my_std = calculate_variance_std(sepal_length_data)\n",
        "print(\"--- 1. 직접 구현한 함수 결과 (n-1로 나눔) ---\")\n",
        "print(f\"표본 분산: {my_variance:.6f}\")\n",
        "print(f\"표본 표준편차: {my_std:.6f}\")\n",
        "\n",
        "# 3. NumPy 라이브러리 결과 비교\n",
        "print(\"\\n--- 2. NumPy 결과 비교 ---\")\n",
        "# 기본값(ddof=0)은 n으로 나눈 모분산을 계산\n",
        "numpy_pop_variance = np.var(sepal_length_data)\n",
        "print(f\"NumPy 모분산 (np.var, ddof=0 기본값): {numpy_pop_variance:.6f}  <-- (결과 다름!)\")\n",
        "# ddof=1 옵션으로 n-1로 나눈 표본 분산을 계산\n",
        "numpy_sample_variance = np.var(sepal_length_data, ddof=1)\n",
        "print(f\"NumPy 표본 분산 (np.var, ddof=1): {numpy_sample_variance:.6f}  <-- (결과 일치!)\")\n",
        "\n",
        "# 4. Pandas 라이브러리 결과 비교\n",
        "print(\"\\n--- 3. Pandas 결과 비교 ---\")\n",
        "# 기본값(ddof=1)으로 표본 분산을 계산\n",
        "pandas_sample_variance = sepal_length_series.var()\n",
        "print(f\"Pandas 표본 분산 (.var(), ddof=1 기본값): {pandas_sample_variance:.6f} <-- (결과 일치!)\")\n",
        "\n",
        "# 5. 최종 검증\n",
        "print(\"\\n--- 4. 최종 검증 ---\")\n",
        "is_correct = np.isclose(my_variance, numpy_sample_variance) and np.isclose(my_variance, pandas_sample_variance)\n",
        "print(f\"직접 구현한 표본 분산이 NumPy(ddof=1) 및 Pandas의 결과와 일치하는가? {'성공' if is_correct else '실패'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbSt-ZFiilLe"
      },
      "source": [
        "## 실습 문제 1.3: 표본 평균의 신뢰도: 표준오차의 이해와 계산\n",
        "\n",
        "**설명**: \\*\\*표준오차(Standard Error, SE)\\*\\*는 \"만약 우리가 모집단에서 지금과 같은 크기($n$)의 표본을 여러 번 반복해서 뽑는다면, 그렇게 얻은 **여러 개의 표본 평균($\\bar{x}$)들**은 얼마나 흩어져 있을까?\"를 추정한 값입니다. 즉, 개별 데이터($x\\_i$)의 흩어짐을 나타내는 **표준편차**와 달리, 표준오차는 \\*\\*통계량인 표본 평균의 변동성(신뢰도)\\*\\*을 나타냅니다. 표준오차가 작을수록, 우리가 가진 단 하나의 표본 평균이 실제 모집단 평균과 가까울 것이라고 더 강하게 신뢰할 수 있습니다.\n",
        "\n",
        "$$SE_{\\bar{x}} = \\frac{s}{\\sqrt{n}}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이' 데이터에서 30개의 샘플을 무작위로 추출하여 `sample_data`를 만드세요.\n",
        "  - `sample_data`의 표본 표준편차($s$)와 표본의 크기($n=30$)를 구하세요.\n",
        "  - 표준편차를 표본 크기의 제곱근으로 나누어 표준오차를 계산하는 `calculate_standard_error` 함수를 완성하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TI9Sev3uikEC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_standard_error(sample: np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  주어진 표본 데이터의 표준오차를 계산합니다.\n",
        "\n",
        "  Args:\n",
        "    sample: 표본 데이터가 담긴 numpy 배열\n",
        "\n",
        "  Returns:\n",
        "    표본 평균의 표준오차\n",
        "  \"\"\"\n",
        "  return sample.std() / np.sqrt(len(sample))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "꽃받침 길이 30개 표본의 표준오차: 0.1257\n"
          ]
        }
      ],
      "source": [
        "sepal_length_data = features_all[:, 0]\n",
        "sample_data = np.random.choice(sepal_length_data, size=30, replace=False)\n",
        "standard_error = calculate_standard_error(sample_data)\n",
        "print(f\"꽃받침 길이 30개 표본의 표준오차: {standard_error:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSqlZ4BAkjti"
      },
      "source": [
        "## 실습 문제 2.1: 확률변수의 기댓값과 큰 수의 법칙\n",
        "\n",
        "**설명**: **확률변수**의 \\*\\*기댓값(Expected Value, E[X])\\*\\*은 그 변수가 평균적으로 어떤 값을 가질 것인지에 대한 이론적인 값입니다. \\*\\*큰 수의 법칙(Law of Large Numbers)\\*\\*에 따르면, 표본의 크기($n$)가 커질수록 우리가 관측한 데이터의 \\*\\*표본 평균($\\bar{x}$)\\*\\*은 확률변수의 \\*\\*기댓값($E[X]$)\\*\\*에 가까워집니다. 따라서 우리는 표본 평균을 이용해 기댓값을 추정할 수 있습니다.\n",
        "\n",
        "$$n \\to \\infty \\implies \\bar{x} \\to E[X]$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이'를 확률변수 $X$로 간주합니다.\n",
        "  - 전체 '꽃받침 길이' 데이터를 사용하여 확률변수 $X$의 기댓값을 추정하세요. (계산은 1.1의 평균과 동일하지만, '데이터의 평균'이 아닌 '확률변수의 기댓값 추정'이라는 의미에 집중해 보세요.)\n",
        "  - `estimate_expected_value` 함수를 완성하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2iKKnPmkxhn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def estimate_expected_value(data: np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  데이터를 바탕으로 확률변수의 기댓값을 추정합니다.\n",
        "\n",
        "  Args:\n",
        "    data: 확률변수의 실현값(표본)이 담긴 numpy 배열\n",
        "\n",
        "  Returns:\n",
        "    추정된 기댓값\n",
        "  \"\"\"\n",
        "  # 큰 수의 법칙에 따라, 표본 평균은 기댓값의 좋은 추정치입니다.\n",
        "  pass\n",
        "\n",
        "\n",
        "sepal_length_data = features_all[:, 0]\n",
        "expected_value = estimate_expected_value(sepal_length_data)\n",
        "print(f\"'꽃받침 길이' 확률변수 X의 추정된 기댓값 E[X]: {expected_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zy4brihk8Kh"
      },
      "source": [
        "## 실습 문제 2.2: 확률변수의 분산과 표준편차 계산하기\n",
        "\n",
        "**설명**: **확률변수**의 \\*\\*분산(Var(X))\\*\\*과 \\*\\*표준편차($\\sigma$)\\*\\*는 확률변수의 값이 기댓값으로부터 평균적으로 얼마나 떨어져 있는지를 나타내는 척도입니다. 즉, 확률변수 자체의 내재된 변동성을 의미합니다. `sepal_length_data`를 이용해 '꽃받침 길이' 확률변수 $X$의 분산을 추정해 보세요.\n",
        "\n",
        "$$Var(X) \\approx s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - E[X])^2$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이' 확률변수 $X$의 기댓값($E[X]$)을 먼저 추정해야 합니다.\n",
        "  - 각 데이터 값과 기댓값의 차이를 제곱하여 모두 더한 뒤, '데이터 개수 - 1'로 나누어 분산을 추정하세요.\n",
        "  - 분산에 제곱근을 취하여 표준편차를 계산하는 `estimate_variance_std` 함수를 완성하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm76sakylLtA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def estimate_variance_std(data: np.ndarray) -> tuple[float, float]:\n",
        "  \"\"\"\n",
        "  데이터를 바탕으로 확률변수의 분산과 표준편차를 추정합니다.\n",
        "\n",
        "  Args:\n",
        "    data: 확률변수의 실현값(표본)이 담긴 numpy 배열\n",
        "\n",
        "  Returns:\n",
        "    (추정된 분산, 추정된 표준편차)를 담은 튜플\n",
        "  \"\"\"\n",
        "  # 표본 분산과 표준편차는 확률변수의 분산과 표준편차의 좋은 추정치입니다.\n",
        "  \n",
        "  pass\n",
        "\n",
        "\n",
        "sepal_length_data = features_all[:, 0]\n",
        "est_variance, est_std_dev = estimate_variance_std(sepal_length_data)\n",
        "\n",
        "print(f\"'꽃받침 길이' 확률변수 X의 추정된 분산 Var(X): {est_variance:.4f}\")\n",
        "print(f\"'꽃받침 길이' 확률변수 X의 추정된 표준편차 \\u03C3: {est_std_dev:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS0WDY_ItT3g"
      },
      "source": [
        "\n",
        "## 실습 문제 2.3: 두 확률변수의 관계: 공분산 계산하기\n",
        "\n",
        "**설명**: \\*\\*공분산(Covariance)\\*\\*은 두 확률변수가 함께 움직이는 **방향성**을 나타내는 값입니다.\n",
        "\n",
        "  - **공분산 \\> 0**: 두 변수가 같은 방향으로 움직이는 경향 (하나가 증가할 때, 다른 하나도 증가)\n",
        "  - **공분산 \\< 0**: 두 변수가 반대 방향으로 움직이는 경향 (하나가 증가할 때, 다른 하나는 감소)\n",
        "\n",
        "공분산의 절댓값 크기만으로는 관계의 강도를 해석하기 어렵지만, 부호를 통해 관계의 방향을 파악할 수 있습니다. '꽃받침 길이'($X$)와 '꽃잎 길이'($Y$)의 공분산을 계산하여 두 변수가 어떤 방향으로 함께 움직이는지 확인해 보세요.\n",
        "\n",
        "$$\\text{cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이'와 '꽃잎 길이' 데이터를 사용하세요.\n",
        "  - 두 변수의 공분산을 계산하는 `calculate_covariance` 함수를 완성하세요.\n",
        "  - 계산된 공분산 값의 부호를 보고 두 변수의 관계 방향을 해석하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VeVHU09taku"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_covariance(data_x: np.ndarray, data_y: np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  두 확률변수 데이터의 표본 공분산을 계산합니다.\n",
        "  \"\"\"\n",
        "\n",
        "  pass\n",
        "\n",
        "\n",
        "sepal_length_data = features_all[:, 0]\n",
        "petal_length_data = features_all[:, 2]\n",
        "my_covariance = calculate_covariance(sepal_length_data, petal_length_data)\n",
        "print(f\"--- 직접 구현한 함수 결과 ---\")\n",
        "print(f\"공분산: {my_covariance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZJAR7ZQlUZN"
      },
      "source": [
        "\n",
        "## 실습 문제 2.4: 공분산의 표준화: 상관계수 계산하기\n",
        "\n",
        "**설명**: \\*\\*상관계수(Correlation Coefficient)\\*\\*는 공분산을 각 변수의 표준편차의 곱으로 나누어 **표준화**한 값입니다. 이 과정을 통해 값의 범위가 항상 -1에서 +1 사이로 고정되어, 변수의 단위와 상관없이 관계의 **방향과 강도**를 객관적으로 비교할 수 있습니다.\n",
        "\n",
        "$$r = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - '꽃받침 길이'와 '꽃잎 길이' 데이터 및 이전 단계에서 구한 공분산 값을 활용하세요.\n",
        "  - 각 변수의 표준편차를 계산한 뒤, 위 공식에 따라 상관계수를 계산하는 `calculate_correlation` 함수를 완성하세요.\n",
        "  - 계산된 상관계수 값을 통해 두 변수 관계의 방향과 강도를 종합적으로 해석하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmhWY_zemmPa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_correlation(data_x: np.ndarray, data_y: np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  두 확률변수 데이터의 피어슨 상관계수를 계산합니다.\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "\n",
        "sepal_length_data = features_all[:, 0]\n",
        "petal_length_data = features_all[:, 2]\n",
        "correlation = calculate_correlation(sepal_length_data, petal_length_data)\n",
        "print(f\"'꽃받침 길이'와 '꽃잎 길이'의 상관계수: {correlation:.4f}\")\n",
        "\n",
        "plt.scatter(sepal_length_data, petal_length_data, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYXXyiT8yt7h"
      },
      "source": [
        "\n",
        "## 실습 문제 2.5: 변수 간 관계 시각화: `pairplot`과 `heatmap`\n",
        "\n",
        "**설명**: 데이터에 포함된 여러 변수들의 관계를 한눈에 파악하는 것은 데이터 분석의 첫걸음입니다. \\*\\*`pairplot`\\*\\*은 모든 변수 쌍에 대한 산점도와 각 변수의 분포를 그려 관계를 시각적으로 탐색하게 해주며, \\*\\*`heatmap`\\*\\*은 상관계수 행렬을 색상으로 표현하여 어떤 변수들이 강한 관계를 갖는지 직관적으로 보여줍니다.\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - `iris` 데이터셋을 Pandas DataFrame으로 사용합니다.\n",
        "  - `seaborn.pairplot()`을 사용하여 `iris` 데이터의 변수 간 관계를 시각화하세요. `hue='species'` 옵션을 추가하여 품종별로 색상을 다르게 표시하세요.\n",
        "  - `DataFrame.corr()` 메소드로 `iris` 데이터의 상관계수 행렬을 계산하세요.\n",
        "  - `seaborn.heatmap()`을 사용하여 위에서 계산한 상관계수 행렬을 시각화하세요. `annot=True` 옵션으로 숫자 값을 표시하고, `cmap='coolwarm'`으로 색상 맵을 지정하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17Qg8Y3MyOfa"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn의 pairplot과 heatmap은 Pandas DataFrame을 사용하는 것이 편리합니다.\n",
        "iris_df = sns.load_dataset('iris')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzyuyY0-zdrH"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = iris_df.drop(columns='species').corr()\n",
        "print(\"상관계수 행렬:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# annot=True: 각 셀에 숫자(상관계수)를 표시\n",
        "# cmap='coolwarm': 색상 맵 지정. 양의 상관은 붉은색, 음의 상관은 푸른색 계열로 표시\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX7y9iQ35qEJ"
      },
      "source": [
        "## 실습 문제 3.1: 동전 던지기 시뮬레이션 함수 구현하기\n",
        "\n",
        "**설명**: 이론적으로 공정한 동전의 앞면이 나올 확률은 50%이지만, 실제 실험에서는 정확히 일치하지 않을 수 있습니다. **시뮬레이션**은 이러한 무작위 실험을 컴퓨터로 수없이 반복하여, 그 결과인 **실험적 확률**이 이론적 확률에 어떻게 근접하는지 관찰하는 강력한 방법입니다. 주어진 횟수만큼 동전을 던지고 그 결과를 반환하는 함수를 직접 구현해 봅시다.\n",
        "\n",
        "$$P(\\text{사건}) = \\frac{\\text{해당 사건이 발생한 횟수}}{\\text{전체 실험 횟수}}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - `simulate_coin_tosses` 함수를 완성하세요.\n",
        "  - 함수 내에서 `num_tosses` 만큼 동전 던지기를 시뮬레이션하세요. (e.g., 0은 뒷면, 1은 앞면)\n",
        "  - 시뮬레이션 결과에서 앞면과 뒷면이 나온 횟수를 각각 계산하세요.\n",
        "  - 계산된 `앞면 횟수`, `뒷면 횟수`, 그리고 전체 `던지기 결과 배열`을 튜플(tuple) 형태로 반환하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = np.random.randint(0,2,100)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cKKDq_Gt5tx9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def simulate_coin_tosses(num_tosses: int) -> tuple[int, int, np.ndarray]:\n",
        "  \"\"\"\n",
        "  주어진 횟수만큼 동전 던지기를 시뮬레이션하고 결과를 반환합니다.\n",
        "\n",
        "  Args:\n",
        "    num_tosses: 총 던지기 횟수\n",
        "\n",
        "  Returns:\n",
        "    (앞면 횟수, 뒷면 횟수, 전체 던지기 결과 배열)을 담은 튜플\n",
        "  \"\"\"\n",
        "  # 여기에 코드를 구현하세요.\n",
        "  result = np.random.randint(0,2,num_tosses)\n",
        "  return  len(result)-result.sum() , result.sum() , result\n",
        "\n",
        "\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-TViVMa66HHY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 던진 횟수: 100\n",
            "앞면이 나온 횟수: 49, 실험적 확률: 0.49\n",
            "뒷면이 나온 횟수: 51, 실험적 확률: 0.51\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_simulations = 100\n",
        "heads, tails, results = simulate_coin_tosses(n_simulations)\n",
        "\n",
        "prob_heads = heads / n_simulations\n",
        "prob_tails = tails / n_simulations\n",
        "\n",
        "print(f\"총 던진 횟수: {n_simulations}\")\n",
        "print(f\"앞면이 나온 횟수: {heads}, 실험적 확률: {prob_heads:.2f}\")\n",
        "print(f\"뒷면이 나온 횟수: {tails}, 실험적 확률: {prob_tails:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKmQRymC6Pem"
      },
      "source": [
        "## 실습 문제 3.2: 두 주사위 합의 확률 분포 시뮬레이션\n",
        "\n",
        "**설명**: 두 사건이 서로에게 영향을 주지 않을 때, 이를 \\*\\*독립 사건(Independent Events)\\*\\*이라고 합니다. 두 개의 공정한 주사위를 던질 때, 첫 번째 주사위의 결과와 두 번째 주사위의 결과는 서로 독립입니다. 따라서 두 사건이 동시에 발생할 확률은 각 사건의 확률을 곱하여 계산할 수 있습니다.\n",
        "\n",
        "이번 실습에서는 두 개의 주사위를 던져 나오는 두 눈의 합을 시뮬레이션합니다. 이 시뮬레이션을 통해 각 합계(2부터 12까지)가 나타나는 실험적 확률 분포를 계산하고, 이론적 확률 분포와 어떻게 유사한지 시각적으로 비교해 봅니다.\n",
        "\n",
        "$$P(A \\cap B) = P(A) \\cdot P(B)$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - `simulate_dice_rolls` 함수를 완성하세요.\n",
        "  - 함수 내에서 `num_rolls` 횟수만큼 두 개의 주사위를 던지는 것을 시뮬레이션하세요.\n",
        "  - 각 시행마다 두 주사위의 눈을 합산하여, 모든 합계가 담긴 배열을 생성하세요.\n",
        "  - 최종적으로, 계산된 합계들의 배열을 반환하세요.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvrGFzBN7cfv"
      },
      "outputs": [],
      "source": [
        "def simulate_dice_rolls(num_rolls: int) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  주어진 횟수만큼 두 개의 주사위를 던져 두 눈의 합을 시뮬레이션합니다.\n",
        "\n",
        "  Args:\n",
        "    num_rolls: 총 던지기 횟수\n",
        "\n",
        "  Returns:\n",
        "    각 시행에서 나온 두 주사위 눈의 합계가 담긴 numpy 배열\n",
        "  \"\"\"\n",
        "  # 여기에 코드를 구현하세요.\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T__BEJQy7j8X"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_simulations = 1000\n",
        "roll_sums = simulate_dice_rolls(n_simulations)\n",
        "\n",
        "# pd.Series.value_counts()를 이용해 각 합계의 빈도를 계산하고 정렬\n",
        "value_counts = pd.Series(roll_sums).value_counts().sort_index()\n",
        "probabilities = value_counts / n_simulations\n",
        "\n",
        "print(f\"--- {n_simulations}번 던지기 시뮬레이션 결과 ---\")\n",
        "print(\"각 합계의 빈도:\")\n",
        "print(value_counts)\n",
        "print(\"\\n각 합계의 실험적 확률:\")\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCCNW0io8rPi"
      },
      "source": [
        "## 실습 문제: 조건부 확률과 학생 데이터 분석\n",
        "\n",
        "**설명**: **조건부 확률**은 특정 사건 B가 일어났다는 조건(정보)이 주어졌을 때, 다른 사건 A가 일어날 확률, 즉 $P(A|B)$를 계산하는 것입니다. 이는 새로운 정보를 바탕으로 특정 사건의 발생 가능성을 어떻게 재평가하는지 이해하는 데 핵심적인 개념입니다. 🧑‍🎓 Pandas를 사용하여 주어진 학생 데이터에서 조건부 확률을 직접 계산하며 데이터 분석의 기초를 다져봅시다.\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\text{A와 B가 동시에 일어나는 경우의 수}}{\\text{B가 일어나는 경우의 수}}$$\n",
        "\n",
        "다음과 같은 학생 설문조사 데이터가 있습니다:\n",
        "\n",
        "| 학생 ID | 전공 | 학년 | 과외활동 참여 |\n",
        "| --- | --- | --- | --- |\n",
        "| 1 | 공학 | 1 | Y |\n",
        "| 2 | 인문 | 2 | N |\n",
        "| 3 | 공학 | 3 | Y |\n",
        "| 4 | 상경 | 2 | N |\n",
        "| 5 | 인문 | 1 | Y |\n",
        "| 6 | 공학 | 4 | N |\n",
        "| 7 | 상경 | 3 | Y |\n",
        "| 8 | 공학 | 2 | Y |\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - 제공된 학생 데이터를 Pandas DataFrame으로 생성하세요.\n",
        "  - 단일 사건의 확률을 계산하는 `calculate_prob` 함수를 완성하세요.\n",
        "  - 조건부 확률 $P(A|B)$를 계산하는 `calculate_conditional_prob` 함수를 완성하세요. 이 함수는 DataFrame과 두 사건(A, B)의 조건(열, 값)을 인자로 받습니다.\n",
        "  - 구현한 함수들을 사용하여 문제에 주어진 네 가지 확률을 모두 계산하세요.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KxqHPfp8wUm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_prob(df: pd.DataFrame, col: str, val) -> float:\n",
        "  \"\"\"\n",
        "  단일 사건의 확률 P(col=val)을 계산합니다.\n",
        "  \"\"\"\n",
        "  # 여기에 코드를 구현하세요.\n",
        "  pass\n",
        "\n",
        "def calculate_conditional_prob(\n",
        "    df: pd.DataFrame,\n",
        "    event_a_col: str, event_a_val,\n",
        "    event_b_col: str, event_b_val\n",
        ") -> float:\n",
        "  \"\"\"\n",
        "  조건부 확률 P(A|B)를 계산합니다.\n",
        "  P(event_a | event_b)\n",
        "  \"\"\"\n",
        "  # 여기에 코드를 구현하세요.\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX7_b14U8zAr"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    '학생 ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    '전공': ['공학', '인문', '공학', '상경', '인문', '공학', '상경', '공학'],\n",
        "    '학년': [1, 2, 3, 2, 1, 4, 3, 2],\n",
        "    '과외활동 참여': ['Y', 'N', 'Y', 'N', 'Y', 'N', 'Y', 'Y']\n",
        "}\n",
        "student_df = pd.DataFrame(data)\n",
        "\n",
        "# --- 테스트 코드 ---\n",
        "# 1. P(전공=공학) 계산\n",
        "prob_engineering = calculate_prob(student_df, '전공', '공학')\n",
        "print(f\"P(전공=공학): {prob_engineering:.4f}\")\n",
        "\n",
        "# 2. P(과외활동=예) 계산\n",
        "prob_activity_yes = calculate_prob(student_df, '과외활동 참여', 'Y')\n",
        "print(f\"P(과외활동=예): {prob_activity_yes:.4f}\")\n",
        "\n",
        "# 3. P(전공=공학 | 과외활동=예) 계산\n",
        "prob_eng_given_activity = calculate_conditional_prob(\n",
        "    student_df,\n",
        "    '전공', '공학',\n",
        "    '과외활동 참여', 'Y'\n",
        ")\n",
        "print(f\"P(전공=공학 | 과외활동=예): {prob_eng_given_activity:.4f}\")\n",
        "\n",
        "# 4. P(과외활동=예 | 전공=공학) 계산\n",
        "prob_activity_given_eng = calculate_conditional_prob(\n",
        "    student_df,\n",
        "    '과외활동 참여', 'Y',\n",
        "    '전공', '공학'\n",
        ")\n",
        "print(f\"P(과외활동=예 | 전공=공학): {prob_activity_given_eng:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
